{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:02:13.963072Z",
     "start_time": "2024-01-09T18:02:13.683084Z"
    }
   },
   "source": [
    "import warnings\n",
    "from loguru import logger\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from edgedroid.models.timings import *\n",
    "import edgedroid.data as default_data\n",
    "\n",
    "logger.enable(\"edgedroid\")\n",
    "\n",
    "data = default_data.load_curve_fitting_data()\n",
    "data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20486260a5187244",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:02:22.737011Z",
     "start_time": "2024-01-09T18:02:13.963119Z"
    }
   },
   "source": [
    "from collections import deque\n",
    "import pandas as pd\n",
    "from typing import Tuple, Deque\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "result_rows = deque()\n",
    "for participant in tqdm(data[\"participant\"].unique(), desc=\"Run\"):\n",
    "    class MultiCurveFittingTestModel(MultiCurveFittingExecutionTimeModel):\n",
    "        @staticmethod\n",
    "        def get_data() -> pd.DataFrame:\n",
    "            data = MultiCurveFittingExecutionTimeModel.get_data()\n",
    "            return data[data[\"participant\"] != participant].copy()\n",
    "        \n",
    "    class PowerFitTestModel(MultiCurveFittingTestModel):\n",
    "        _fit_functions = (PowerFit,)\n",
    "        \n",
    "    class SquareFitTestModel(MultiCurveFittingTestModel):\n",
    "        _fit_functions = (SquareFit,)\n",
    "        \n",
    "    class CubeFitTestModel(MultiCurveFittingTestModel):\n",
    "        _fit_functions = (CubeFit,)\n",
    "        \n",
    "    class ExponentialFitTestModel(MultiCurveFittingTestModel):\n",
    "        _fit_functions = (ExponentialFit,)\n",
    "        \n",
    "    def get_test_data(*args, **kwargs) -> (\n",
    "        Tuple[\n",
    "            pd.DataFrame,\n",
    "            pd.arrays.IntervalArray,\n",
    "            pd.arrays.IntervalArray,\n",
    "            pd.arrays.IntervalArray,\n",
    "        ]\n",
    "    ):\n",
    "        data, *rest = ExecutionTimeModel.get_data()\n",
    "        return (data[data[\"run_id\"] != participant].copy(), *rest)\n",
    "\n",
    "    class EmpiricalTestModel(EmpiricalETM):\n",
    "        get_data = get_test_data\n",
    "        \n",
    "    class EmpiricalMeanTestModel(EmpiricalAggregateETM):\n",
    "        get_data = get_test_data\n",
    "        \n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, aggregate_fn=np.mean, **kwargs)\n",
    "            \n",
    "    class EmpiricalMedianTestModel(EmpiricalAggregateETM):\n",
    "        get_data = get_test_data\n",
    "        \n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, aggregate_fn=np.median, **kwargs)\n",
    "        \n",
    "    class TheoreticalTestModel(FittedETM):\n",
    "        get_data = get_test_data\n",
    "\n",
    "    class NaiveTestModel(FirstOrderETM):\n",
    "        get_data = get_test_data\n",
    "        \n",
    "    class NaiveAggTestModel(FirstOrderAggregateETM):\n",
    "        get_data = get_test_data\n",
    "        \n",
    "    cleanup = CleanupMode.TRUNCATE\n",
    "    \n",
    "    run_data = data[data[\"participant\"] == participant].copy()\n",
    "\n",
    "    neuroticism = run_data[\"neuroticism\"].unique()[0]\n",
    "    naive_model = NaiveTestModel()\n",
    "    naive_mean_model = NaiveAggTestModel(np.mean)\n",
    "    naive_median_model = NaiveAggTestModel(np.median)\n",
    "    # curve_fitting_model = CurveFittingTestModel(neuroticism)\n",
    "    \n",
    "    power_fit_model = PowerFitTestModel(neuroticism)\n",
    "    square_fit_model = SquareFitTestModel(neuroticism)\n",
    "    cube_fit_model = CubeFitTestModel(neuroticism)\n",
    "    exponential_fit_model = ExponentialFitTestModel(neuroticism)\n",
    "    multi_fit_model = MultiCurveFittingExecutionTimeModel(neuroticism)\n",
    "    \n",
    "    # deque containing (model name, model object, ttf_bins, window_size, kernel name)\n",
    "    models: Deque[Tuple[str, ExecutionTimeModel, int, int, str]] = deque()\n",
    "    models.extend((\n",
    "        (\"1st order\", naive_model, 0, 0, \"none\"),\n",
    "        (\"1st order (median)\", naive_median_model, 0, 0, \"none\"),\n",
    "        (\"1st order (mean)\", naive_mean_model, 0, 0, \"none\"),\n",
    "        (\"a * x^b + c\", power_fit_model , 0, 0, \"none\"),\n",
    "        (\"a * x^2 + b * x + c\", square_fit_model, 0, 0, \"none\"),\n",
    "        (\"a * x^3 + b * x^2 + c * x + d\", cube_fit_model, 0, 0, \"none\"),\n",
    "        (\"a * e^x + b\", exponential_fit_model, 0, 0, \"none\"),\n",
    "        (\"multi curve\", multi_fit_model, 0, 0, \"none\")\n",
    "    ))\n",
    "    \n",
    "    # for (ttf_bins, window_size) in itertools.product(range(1, 10), (4, 8, 12)):\n",
    "    #     exp_kernel = ExponentialTTFWindowKernel(window_size=window_size)\n",
    "    #     steep_linear_kernel = LinearTTFWindowKernel(window_size=window_size, max_relative_weight=10)\n",
    "    #     shallow_linear_kernel = LinearTTFWindowKernel(window_size=window_size, max_relative_weight=2)\n",
    "    #     average_kernel = AverageTTFWindowKernel(window_size=window_size)\n",
    "    #     \n",
    "    #     kernels = (\n",
    "    #         (\"exponential\", exp_kernel),\n",
    "    #         (\"linear_steep\", steep_linear_kernel),\n",
    "    #         (\"linear_shallow\", shallow_linear_kernel),\n",
    "    #         (\"average\", average_kernel)\n",
    "    #     )\n",
    "    #     model_classes = (\n",
    "    #         (\"empirical\", EmpiricalTestModel),\n",
    "    #         (\"empirical (mean)\", EmpiricalMeanTestModel),\n",
    "    #         (\"empirical (median)\", EmpiricalMedianTestModel),\n",
    "    #         (\"theoretical\", TheoreticalTestModel)\n",
    "    #     )\n",
    "    #     \n",
    "    #     for (class_name, model_cls), (kernel_name, kernel) in itertools.product(model_classes, kernels):\n",
    "    #         m = model_cls(kernel=kernel, neuroticism=neuroticism, ttf_levels=ttf_bins, cleanup=cleanup)\n",
    "    #         models.append((class_name, m, ttf_bins, window_size, kernel_name))\n",
    "        \n",
    "    for _ in range(1):\n",
    "        for i, (prev_ttf, exec_time, neuro, prev_duration) in enumerate(run_data[[\"prev_ttf\", \"exec_time\", \"neuro\", \"prev_duration\"]].itertuples(index=False)):\n",
    "            for model_name, model, ttf_bins, window_size, kernel_name in models:\n",
    "                if i == 0:\n",
    "                    # reset the model between runs\n",
    "                    model.reset()\n",
    "                else:\n",
    "                    # first row has no previous ttf\n",
    "                    model.advance(prev_ttf)\n",
    "                    \n",
    "                prediction = model.get_execution_time()\n",
    "                error = prediction - exec_time\n",
    "                result_rows.append({\n",
    "                    \"real\": exec_time,\n",
    "                    \"prediction\": prediction,\n",
    "                    \"error\": error,\n",
    "                    \"sqr_error\": np.square(error),\n",
    "                    \"model\": model_name,\n",
    "                    \"duration\": prev_duration,\n",
    "                    \"neuro\": neuro,\n",
    "                    # \"kernel\": kernel_name,\n",
    "                    # \"ttf_bins\": ttf_bins,\n",
    "                    # \"window_size\": window_size,\n",
    "                })\n",
    "\n",
    "results = pd.DataFrame(result_rows)\n",
    "for col in (\"model\", ):  # \"kernel\"):\n",
    "    results[col] = results[col].astype(\"category\")\n",
    "\n",
    "results.to_parquet(\"./full_validation.parquet\")\n",
    "results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# results.groupby([\"model\", \"kernel\", \"window_size\", \"ttf_bins\"], observed=True)[\"sqr_error\"].mean().sort_values(ascending=True)\n",
    "\n",
    "results.groupby([\"model\", \"neuro\", \"duration\"], observed=True)[\"sqr_error\"].mean().sort_values(ascending=True)\n",
    "\n",
    "# look at neuroticism\n",
    "# look at durations\n",
    "# look different functions\n",
    "# look at delta in ttf to reset duration (maybe not instantaneous delta)\n",
    "\n",
    "# look at different curves for each quadrant"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:02:22.886985Z",
     "start_time": "2024-01-09T18:02:22.694017Z"
    }
   },
   "id": "a36996e5acb77c8a",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "results.groupby([\"model\"], observed=True)[\"sqr_error\"].describe().sort_values(by=\"mean\", ascending=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:02:22.888031Z",
     "start_time": "2024-01-09T18:02:22.859019Z"
    }
   },
   "id": "77b7b5cc192a3775",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e70efda-85b2-47cd-acee-b0cca3789db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-09T18:02:22.888670Z",
     "start_time": "2024-01-09T18:02:22.875502Z"
    }
   },
   "source": [
    "# # %matplotlib inline\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# \n",
    "# fg = sns.catplot(results, kind=\"point\", x=\"ttf_bins\", y=\"sqr_error\", hue=\"model_tag\", height=5, aspect=2)\n",
    "# fg.set(ylim=(0, None))\n",
    "# fg.set_ylabels(\"MSE\")\n",
    "# for ax in fg.axes.flat:\n",
    "#     ax.set_xticks(ax.get_xticks(), ax.get_xticklabels(), rotation=45, ha='right')\n",
    "# plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# results.groupby([\"model\", \"ttf_bins\", \"cleanup\"])[\"sqr_error\"].mean().sort_values()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:02:22.959287Z",
     "start_time": "2024-01-09T18:02:22.879938Z"
    }
   },
   "id": "9e6d4e99e1e28c7c",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-09T18:02:22.974371Z",
     "start_time": "2024-01-09T18:02:22.884557Z"
    }
   },
   "id": "f9c3c060a0112fca",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
