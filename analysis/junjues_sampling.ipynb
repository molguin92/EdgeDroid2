{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import itertools as it\n",
    "import warnings\n",
    "from collections import deque\n",
    "from typing import Dict\n",
    "\n",
    "import multiprocess as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from edgedroid.models import *\n",
    "from sampling_util import *\n",
    "\n",
    "reference_name = \"Adaptive\\nGaussian fit\"\n",
    "\n",
    "def experimental_run(\n",
    "        repetition: int,\n",
    "        task_steps: int,\n",
    "        rtt: float,\n",
    ") -> pd.DataFrame:\n",
    "    min_sr = 0.5\n",
    "    alpha = 3.0\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ground_truths: Dict[str, ExecutionTimeModel] = {\n",
    "            \"Low\" : ExpKernelRollingTTFETModel(neuroticism=0.0),\n",
    "            \"High\": ExpKernelRollingTTFETModel(neuroticism=1.0)\n",
    "        }\n",
    "\n",
    "        samplers: Dict[str, Sampler] = {\n",
    "            \"Greedy\"                                : GreedySampler(),\n",
    "            reference_name: JunjuesSampler(\n",
    "                cdf=FittedNaiveExecutionTimeModel(dist=stats.norm).get_cdf_at_instant,\n",
    "                min_sr=min_sr,\n",
    "                alpha=alpha,\n",
    "            ),\n",
    "            \"Adaptive\\nED2, low neuro\"                 : JunjuesSampler(\n",
    "                cdf=ExpKernelRollingTTFETModel(neuroticism=0.0).get_cdf_at_instant,\n",
    "                min_sr=min_sr,\n",
    "                alpha=alpha,\n",
    "            ),\n",
    "            \"Adaptive\\nED2, high neuro\"                 : JunjuesSampler(\n",
    "                cdf=ExpKernelRollingTTFETModel(neuroticism=1.0).get_cdf_at_instant,\n",
    "                min_sr=min_sr,\n",
    "                alpha=alpha,\n",
    "            ),\n",
    "            \"Adaptive\\nED2 ExG, low neuro\"        : JunjuesSampler(\n",
    "                cdf=DistExpKernelRollingTTFETModel(neuroticism=0.0, dist=stats.exponnorm).get_cdf_at_instant,\n",
    "                min_sr=min_sr,\n",
    "                alpha=alpha,\n",
    "            ),\n",
    "            \"Adaptive\\nED2 ExG, high neuro\"        : JunjuesSampler(\n",
    "                cdf=DistExpKernelRollingTTFETModel(neuroticism=1.0, dist=stats.exponnorm).get_cdf_at_instant,\n",
    "                min_sr=min_sr,\n",
    "                alpha=alpha,\n",
    "            ),\n",
    "        }\n",
    "\n",
    "    rows = deque()\n",
    "\n",
    "    for (gt_name, gt), (s_name, sampler) in it.product(ground_truths.items(), samplers.items()):\n",
    "        gt.reset()\n",
    "        prev_ttf = rtt\n",
    "\n",
    "        for step in range(1, task_steps + 1):\n",
    "            exec_time = gt.advance(prev_ttf).get_execution_time()\n",
    "            sampling_result = sampler(exec_time, rtt)\n",
    "\n",
    "            ttf = sampling_result.duration - exec_time\n",
    "            wait_time = ttf - rtt\n",
    "\n",
    "            rows.append({\n",
    "                \"ground_truth\": gt_name,\n",
    "                \"sampler\"     : s_name,\n",
    "                \"rtt\"         : rtt,\n",
    "                \"repetition\"  : repetition,\n",
    "                \"step\"        : step,\n",
    "                \"exec_time\"   : exec_time,\n",
    "                \"duration\"    : sampling_result.duration,\n",
    "                \"ttf\"         : ttf,\n",
    "                \"wait_time\"   : wait_time,\n",
    "                \"num_samples\" : sampling_result.num_samples,\n",
    "            })\n",
    "\n",
    "            prev_ttf = ttf\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"ground_truth\"] = df[\"ground_truth\"].astype(pd.CategoricalDtype(ground_truths.keys(), ordered=False))\n",
    "    df[\"sampler\"] = df[\"sampler\"].astype(pd.CategoricalDtype(samplers.keys(), ordered=False))\n",
    "    return df\n",
    "\n",
    "\n",
    "rtts = [0.15, 0.3, 0.6]\n",
    "repetitions = 100\n",
    "num_steps = 100\n",
    "\n",
    "results = deque()\n",
    "combs = list(it.product(rtts, range(1, repetitions + 1)))\n",
    "\n",
    "with tqdm(total=len(combs)) as bar, mp.Pool() as pool:\n",
    "    def _callback(df: pd.DataFrame):\n",
    "        results.append(df)\n",
    "        bar.update()\n",
    "\n",
    "\n",
    "    def _errback(error):\n",
    "        raise error\n",
    "\n",
    "\n",
    "    for rtt, rep in combs:\n",
    "        pool.apply_async(\n",
    "            experimental_run,\n",
    "            kwds=dict(repetition=rep, task_steps=num_steps, rtt=rtt),\n",
    "            callback=_callback,\n",
    "            error_callback=_errback,\n",
    "        )\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "results = pd.concat(results)\n",
    "results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\", font_scale=2.5)\n",
    "sns.set_palette(\"Dark2\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "source": [
    "# mean number of samples per rep\n",
    "samples_per_rep = results.groupby([\"ground_truth\", \"sampler\", \"rtt\", \"repetition\"])[\"num_samples\"].mean().reset_index()\n",
    "samples_per_rep[\"rtt\"] = samples_per_rep[\"rtt\"].apply(lambda e: f\"{int(e * 1000):} ms\").astype(str)\n",
    "samples_per_rep"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "source": [
    "# import numpy as np\n",
    "\n",
    "# order = [\"Adaptive (ED2 LN)\", \"Adaptive (ED2 HN)\", \"Adaptive (ED2 LN, ExG fit)\", \"Adaptive (ED2 HN, ExG fit)\",\n",
    "#          \"Adaptive (reference, gaussian fit)\", \"Greedy\"]\n",
    "\n",
    "fg = sns.catplot(\n",
    "    kind=\"bar\",\n",
    "    # join=False,\n",
    "    data=samples_per_rep,\n",
    "    x=\"num_samples\",\n",
    "    hue=\"rtt\",\n",
    "    y=\"sampler\",\n",
    "    # order=order,\n",
    "    col=\"ground_truth\",\n",
    "    aspect=3,\n",
    "    height=8,\n",
    ")\n",
    "# fg.set(xticks=np.linspace(0, 40, 5))\n",
    "fg.legend.set_title(\"RTT\")\n",
    "fg.set_axis_labels(\"Samples per step\", \"Sampling\\nscheme\")\n",
    "# for ax in fg.axes.flat:\n",
    "#     for i in ax.containers:\n",
    "#         ax.bar_label(i, padding=-50, fmt=\"%0.2f\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "source": [
    "ix = pd.IndexSlice\n",
    "\n",
    "table = (\n",
    "    samples_per_rep\n",
    "    .groupby([\"ground_truth\", \"sampler\", \"rtt\"], observed=True)\n",
    "    [\"num_samples\"]\n",
    "    .mean()\n",
    "    .unstack()\n",
    ")\n",
    "table.columns = [r\"\\SI{\" f\"{int(e.split()[0]):3d}\" r\"}{\\milli\\second}\" for e in table.columns]\n",
    "print(\n",
    "    table\n",
    "    # .loc[order]\n",
    "    .loc[ix[:, [\"Greedy\", reference_name], :]]\n",
    "    # .stack()\n",
    "    # .unstack(level=0)\n",
    "    # .stack(level=0)\n",
    "    .style\n",
    "    .format(lambda e: r\"\\num{\" f\"{e:0.2f}\" r\"}\")\n",
    "    .to_latex()\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "source": [
    "import pingouin as pg\n",
    "\n",
    "ix = pd.IndexSlice\n",
    "\n",
    "\n",
    "def diff_wrt_ref_rtt(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    ref_samples = df.loc[df[\"sampler\"] == reference_name, \"num_samples\"].to_numpy()\n",
    "    ref_mean = ref_samples.mean()\n",
    "\n",
    "    def diff_wrt_ref(samples: pd.Series) -> pd.Series:\n",
    "        ttest = pg.ttest(samples.to_numpy(), ref_samples, alternative=\"two-sided\")\n",
    "        diff_raw = samples.mean() - ref_mean\n",
    "        diff = diff_raw / ref_mean\n",
    "        ci = ttest.at[\"T-test\", \"CI95%\"]\n",
    "\n",
    "        pval = ttest.at[\"T-test\", \"p-val\"]\n",
    "        sig_pval = pval < 0.05\n",
    "\n",
    "        return pd.Series({\n",
    "            \"diff\"     : diff,\n",
    "            \"diff_raw\" : diff_raw,\n",
    "            \"p-val\"    : pval,\n",
    "            \"p < 0.05\" : sig_pval,\n",
    "            \"CI95_Low\" : ci[0] / ref_mean,\n",
    "            \"CI95_High\": ci[1] / ref_mean}, name=\"Result\")\n",
    "\n",
    "    return df.groupby(\"sampler\")[\"num_samples\"].apply(diff_wrt_ref)\n",
    "\n",
    "\n",
    "samples_diff = samples_per_rep.groupby([\"ground_truth\", \"rtt\"]).apply(diff_wrt_ref_rtt).stack().stack().unstack(level=2).reset_index()\n",
    "samples_diff = samples_diff[samples_diff[\"sampler\"] != reference_name]\n",
    "samples_diff[\"sampler\"] = samples_diff[\"sampler\"].cat.remove_unused_categories()\n",
    "samples_diff"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "source": [
    "import matplotlib.ticker as tkr\n",
    "\n",
    "plot_data = samples_diff.set_index([\"ground_truth\", \"sampler\", \"rtt\"])[\n",
    "    [\"CI95_Low\", \"CI95_High\", \"diff\"]].stack().reset_index().rename(columns={0: \"values\"})\n",
    "# plot_data[\"values\"] = plot_data[\"values\"] * -1\n",
    "\n",
    "fg = sns.catplot(\n",
    "    kind=\"bar\",\n",
    "    data=plot_data,\n",
    "    estimator=lambda e: sorted(e)[1],\n",
    "    errorbar=lambda e: (min(e), max(e)),\n",
    "    y=\"sampler\",\n",
    "    hue=\"rtt\",\n",
    "    x=\"values\",\n",
    "    # order=[\"Adaptive (ED2 LN)\", \"Adaptive (ED2 HN)\", \"Adaptive (ED2 LN, ExG fit)\", \"Adaptive (ED2 HN, ExG fit)\", ],\n",
    "    # hue=\"Configuration\",\n",
    "    col=\"ground_truth\",\n",
    "    aspect=3,\n",
    "    height=4,\n",
    "    # yerr=duration_diff[\"CI95%\"].to_numpy(),\n",
    ")\n",
    "fg.legend.set_title(\"RTT\")\n",
    "fg.set_axis_labels(\"Diff. in mean number of samples w.r.t. reference\", \"Samplign\\nScheme\")\n",
    "# fg.set(xticks=np.linspace(-0.25, 0, 6))\n",
    "for ax in fg.axes.flat:\n",
    "    ax.xaxis.set_major_formatter(tkr.FuncFormatter(lambda x, p: f\"{x:0.0%}\" if x != 0.0 else \"0%\"))\n",
    "plt.show()\n",
    "\n",
    "def plot_by_ground_truth(data: pd.DataFrame, *args, **kwargs) -> None:\n",
    "    # print(args, kwargs)\n",
    "    ax = plt.gca()\n",
    "    gt_label = data[\"ground_truth\"].unique()[0]\n",
    "    if gt_label == \"Low\":\n",
    "        filter_neuro = \"low\"\n",
    "    else:\n",
    "        filter_neuro = \"high\"\n",
    "\n",
    "    data = data[\n",
    "        data[\"sampler\"].astype(str).str.contains(filter_neuro)\n",
    "        # | (gt_low[\"sampler\"] == \"Greedy\")\n",
    "        | (data[\"sampler\"] == reference_name)\n",
    "    ].copy()\n",
    "    data[\"sampler\"] = data[\"sampler\"].cat.remove_unused_categories()\n",
    "\n",
    "    sns.barplot(\n",
    "        data=data,\n",
    "        x=\"values\",\n",
    "        hue=\"rtt\",\n",
    "        y=\"sampler\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.legend()\n",
    "\n",
    "fg = sns.FacetGrid(plot_data, col=\"ground_truth\", aspect=2.5, sharey=False, height=4)\n",
    "fg.map_dataframe(plot_by_ground_truth)\n",
    "fg.add_legend(title=\"RTT\", borderpad=2)\n",
    "# fg.legend.set_title(\"RTT\")\n",
    "fg.set_axis_labels(\"Difference in mean number of\\nsamples w.r.t. reference\", \"Samplign\\nScheme\")\n",
    "fg.set_titles(col_template=\"{col_name} neuroticism external timing model\")\n",
    "fg.set(xticks=np.linspace(-0.3, 0.0, 6))\n",
    "for ax in fg.axes.flat:\n",
    "    ax.xaxis.set_major_formatter(tkr.FuncFormatter(lambda x, p: f\"{x:+0.0%}\" if x != 0.0 else \"0%\"))\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
