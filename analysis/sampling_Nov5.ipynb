{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/1400 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dfa175432b7446a9fef5956e7090e2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "        ground_truth          sampler neuroticism  repetition  execution_time  \\\n0                low           Greedy         n/a           6        2.544408   \n1                low           Greedy         n/a           6        3.925021   \n2                low           Greedy         n/a           6        3.550687   \n3                low           Greedy         n/a           6        4.169947   \n4                low           Greedy         n/a           6        3.187233   \n...              ...              ...         ...         ...             ...   \n1959995         high  Offline optimum         n/a         100       12.797898   \n1959996         high  Offline optimum         n/a         100        7.387067   \n1959997         high  Offline optimum         n/a         100        3.704197   \n1959998         high  Offline optimum         n/a         100        5.932111   \n1959999         high  Offline optimum         n/a         100        2.533906   \n\n          duration  rtt       ttf     wait_time  num_samples    energy     P0  \\\n0         3.000000  0.3  0.455592  1.555922e-01           10  0.060000  0.015   \n1         4.500000  0.3  0.574979  2.749787e-01           15  0.090000  0.015   \n2         3.900000  0.3  0.349313  4.931259e-02           13  0.078000  0.015   \n3         4.500000  0.3  0.330053  3.005289e-02           15  0.090000  0.015   \n4         3.600000  0.3  0.412767  1.127669e-01           12  0.072000  0.015   \n...            ...  ...       ...           ...          ...       ...    ...   \n1959995  16.997898  4.2  4.200000 -8.881784e-16            1  0.373468  0.015   \n1959996  11.587067  4.2  4.200000  0.000000e+00            1  0.292306  0.015   \n1959997   7.904197  4.2  4.200000  0.000000e+00            1  0.237063  0.015   \n1959998  10.132111  4.2  4.200000 -8.881784e-16            1  0.270482  0.015   \n1959999   6.733906  4.2  4.200000  8.881784e-16            1  0.219509  0.015   \n\n            Pc    t0    tc  \n0        0.045  0.25  0.05  \n1        0.045  0.25  0.05  \n2        0.045  0.25  0.05  \n3        0.045  0.25  0.05  \n4        0.045  0.25  0.05  \n...        ...   ...   ...  \n1959995  0.045  0.25  3.95  \n1959996  0.045  0.25  3.95  \n1959997  0.045  0.25  3.95  \n1959998  0.045  0.25  3.95  \n1959999  0.045  0.25  3.95  \n\n[1960000 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ground_truth</th>\n      <th>sampler</th>\n      <th>neuroticism</th>\n      <th>repetition</th>\n      <th>execution_time</th>\n      <th>duration</th>\n      <th>rtt</th>\n      <th>ttf</th>\n      <th>wait_time</th>\n      <th>num_samples</th>\n      <th>energy</th>\n      <th>P0</th>\n      <th>Pc</th>\n      <th>t0</th>\n      <th>tc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>low</td>\n      <td>Greedy</td>\n      <td>n/a</td>\n      <td>6</td>\n      <td>2.544408</td>\n      <td>3.000000</td>\n      <td>0.3</td>\n      <td>0.455592</td>\n      <td>1.555922e-01</td>\n      <td>10</td>\n      <td>0.060000</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.25</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>low</td>\n      <td>Greedy</td>\n      <td>n/a</td>\n      <td>6</td>\n      <td>3.925021</td>\n      <td>4.500000</td>\n      <td>0.3</td>\n      <td>0.574979</td>\n      <td>2.749787e-01</td>\n      <td>15</td>\n      <td>0.090000</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.25</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>low</td>\n      <td>Greedy</td>\n      <td>n/a</td>\n      <td>6</td>\n      <td>3.550687</td>\n      <td>3.900000</td>\n      <td>0.3</td>\n      <td>0.349313</td>\n      <td>4.931259e-02</td>\n      <td>13</td>\n      <td>0.078000</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.25</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>low</td>\n      <td>Greedy</td>\n      <td>n/a</td>\n      <td>6</td>\n      <td>4.169947</td>\n      <td>4.500000</td>\n      <td>0.3</td>\n      <td>0.330053</td>\n      <td>3.005289e-02</td>\n      <td>15</td>\n      <td>0.090000</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.25</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>low</td>\n      <td>Greedy</td>\n      <td>n/a</td>\n      <td>6</td>\n      <td>3.187233</td>\n      <td>3.600000</td>\n      <td>0.3</td>\n      <td>0.412767</td>\n      <td>1.127669e-01</td>\n      <td>12</td>\n      <td>0.072000</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.25</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1959995</th>\n      <td>high</td>\n      <td>Offline optimum</td>\n      <td>n/a</td>\n      <td>100</td>\n      <td>12.797898</td>\n      <td>16.997898</td>\n      <td>4.2</td>\n      <td>4.200000</td>\n      <td>-8.881784e-16</td>\n      <td>1</td>\n      <td>0.373468</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.25</td>\n      <td>3.95</td>\n    </tr>\n    <tr>\n      <th>1959996</th>\n      <td>high</td>\n      <td>Offline optimum</td>\n      <td>n/a</td>\n      <td>100</td>\n      <td>7.387067</td>\n      <td>11.587067</td>\n      <td>4.2</td>\n      <td>4.200000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.292306</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.25</td>\n      <td>3.95</td>\n    </tr>\n    <tr>\n      <th>1959997</th>\n      <td>high</td>\n      <td>Offline optimum</td>\n      <td>n/a</td>\n      <td>100</td>\n      <td>3.704197</td>\n      <td>7.904197</td>\n      <td>4.2</td>\n      <td>4.200000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.237063</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.25</td>\n      <td>3.95</td>\n    </tr>\n    <tr>\n      <th>1959998</th>\n      <td>high</td>\n      <td>Offline optimum</td>\n      <td>n/a</td>\n      <td>100</td>\n      <td>5.932111</td>\n      <td>10.132111</td>\n      <td>4.2</td>\n      <td>4.200000</td>\n      <td>-8.881784e-16</td>\n      <td>1</td>\n      <td>0.270482</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.25</td>\n      <td>3.95</td>\n    </tr>\n    <tr>\n      <th>1959999</th>\n      <td>high</td>\n      <td>Offline optimum</td>\n      <td>n/a</td>\n      <td>100</td>\n      <td>2.533906</td>\n      <td>6.733906</td>\n      <td>4.2</td>\n      <td>4.200000</td>\n      <td>8.881784e-16</td>\n      <td>1</td>\n      <td>0.219509</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.25</td>\n      <td>3.95</td>\n    </tr>\n  </tbody>\n</table>\n<p>1960000 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "from collections import deque\n",
    "from typing import Dict\n",
    "\n",
    "import multiprocess as mp\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from edgedroid.models import *\n",
    "from sampling_util import *\n",
    "\n",
    "reference_name = \"Offline optimum\"\n",
    "\n",
    "\n",
    "def experimental_run(\n",
    "        rtt: float,\n",
    "        proc_t: float,\n",
    "        P0: float,\n",
    "        Pc: float,\n",
    "        task_steps: int,\n",
    "        repetition: int,\n",
    "):\n",
    "    tc = rtt - proc_t\n",
    "    w0 = 1.0\n",
    "    min_sr = 1 / (2 * w0)\n",
    "    alpha = 1.5\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ground_truths = {\n",
    "            \"low\" : ExpKernelRollingTTFETModel(neuroticism=0.0),\n",
    "            \"high\": ExpKernelRollingTTFETModel(neuroticism=1.0)\n",
    "        }\n",
    "\n",
    "        samplers: Dict[str, Dict[str, ConstantRTTSampler]] = {\n",
    "            \"Greedy\"                           : {\n",
    "                \"n/a\": GreedyConstantRTTSampler(\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            \"Wang et. al. 2019\\nGaussian fit\"  : {\n",
    "                \"n/a\": JunjuesConstantRTTSampler(\n",
    "                    cdf_estimator=FittedNaiveExecutionTimeModel(dist=stats.norm),\n",
    "                    min_sr=min_sr,\n",
    "                    alpha=alpha,\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            \"Sample-count-optimized\\naperiodic\": {\n",
    "                \"low\" : SamplingOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=0.0),\n",
    "                    max_wait=w0,\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                ),\n",
    "                \"high\": SamplingOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=1.0),\n",
    "                    max_wait=w0,\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            \"Energy-optimized\\naperiodic\"      : {\n",
    "                \"low\" : EnergyOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=0.0),\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                ),\n",
    "                \"high\": EnergyOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=1.0),\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            reference_name                     : {\n",
    "                \"n/a\": IdealConstantRTTSampler(\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "        }\n",
    "\n",
    "    rows = deque()\n",
    "\n",
    "    for (gt_level, ground_truth), (sampler_name, sampler_neuro_levels) in itertools.product(ground_truths.items(),\n",
    "                                                                                            samplers.items()):\n",
    "        for neuro_level, sampler in sampler_neuro_levels.items():\n",
    "            ground_truth.reset()\n",
    "            sampler.reset()\n",
    "            prev_ttf = rtt\n",
    "\n",
    "            for step in range(1, task_steps + 1):\n",
    "                exec_time = ground_truth.advance(prev_ttf).get_execution_time()\n",
    "                step_results: StepResults = sampler.sample_step(prev_ttf, exec_time)\n",
    "\n",
    "                rows.append(dict(\n",
    "                    ground_truth=gt_level,\n",
    "                    sampler=sampler_name,\n",
    "                    neuroticism=neuro_level,\n",
    "                    repetition=repetition,\n",
    "                    **step_results._asdict(),\n",
    "                ))\n",
    "                prev_ttf = step_results.ttf\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"sampler\"] = df[\"sampler\"].astype(pd.CategoricalDtype(samplers.keys(), ordered=False))\n",
    "    df[\"ground_truth\"] = df[\"ground_truth\"].astype(pd.CategoricalDtype([\"low\", \"high\"], ordered=True))\n",
    "    df[\"neuroticism\"] = df[\"neuroticism\"].astype(pd.CategoricalDtype([\"n/a\", \"low\", \"high\"], ordered=True))\n",
    "    return df\n",
    "\n",
    "\n",
    "processing_delay = 0.250\n",
    "rtts = np.linspace(0.3, 4.2, 14)\n",
    "net_delays = rtts - processing_delay\n",
    "\n",
    "task_steps = 100\n",
    "repetitions = 100\n",
    "\n",
    "P0 = 0.015\n",
    "Pc = 0.045\n",
    "\n",
    "combinations = list(itertools.product(\n",
    "    rtts,\n",
    "    range(1, repetitions + 1)\n",
    "))\n",
    "\n",
    "results = deque()\n",
    "\n",
    "with tqdm(total=len(combinations)) as bar, mp.Pool() as pool:\n",
    "    def _callback(df: pd.DataFrame):\n",
    "        results.append(df)\n",
    "        bar.update()\n",
    "\n",
    "\n",
    "    def _errback(error):\n",
    "        print(error)\n",
    "        raise error\n",
    "\n",
    "\n",
    "    for rtt, rep in combinations:\n",
    "        pool.apply_async(\n",
    "            experimental_run,\n",
    "            args=(rtt, processing_delay, P0, Pc, task_steps, rep),\n",
    "            callback=_callback,\n",
    "            error_callback=_errback,\n",
    "        )\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "results = pd.concat(results, ignore_index=True)\n",
    "results.to_parquet(\"./final_sampling_results.parquet.gzip\", compression=\"gzip\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# class SuperNeuroticModel(ExpKernelRollingTTFETModel):\n",
    "#     @staticmethod\n",
    "#     def get_data() -> Tuple[\n",
    "#         pd.DataFrame,\n",
    "#         pd.arrays.IntervalArray,\n",
    "#         pd.arrays.IntervalArray,\n",
    "#         pd.arrays.IntervalArray,\n",
    "#     ]:\n",
    "#         scaling_factor_min: float = 0.25\n",
    "#         scaling_factor_max: float = 4\n",
    "#\n",
    "#         data, *r = ExpKernelRollingTTFETModel.get_data()\n",
    "#         # print(data)\n",
    "#\n",
    "#         old_min = data[\"exec_time\"].min()\n",
    "#         old_max = data[\"exec_time\"].max()\n",
    "#\n",
    "#         new_min = old_min * scaling_factor_min\n",
    "#         new_max = old_max * scaling_factor_max\n",
    "#         new_range = new_max - new_min\n",
    "#\n",
    "#         data[\"exec_time\"] = (data[\"exec_time\"] - old_min) / (old_max - old_min)\n",
    "#         data[\"exec_time\"] = (data[\"exec_time\"] * new_range) + new_min\n",
    "#\n",
    "#         return data, *r\n",
    "#\n",
    "#\n",
    "# def superneurotic_experimental_run(\n",
    "#         rtt: float,\n",
    "#         proc_t: float,\n",
    "#         P0: float,\n",
    "#         Pc: float,\n",
    "#         task_steps: int,\n",
    "#         repetition: int,\n",
    "# ):\n",
    "#     tc = rtt - proc_t\n",
    "#     calc_energy = lambda result: calculate_energy(P0, Pc, tc, result)\n",
    "#\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\")\n",
    "#         ground_truth = SuperNeuroticModel(neuroticism=1.0)\n",
    "#         samplers: Dict[str, Sampler] = {\n",
    "#             \"Greedy\"                                     : GreedySampler(),\n",
    "#             \"Ideal\"                                      : IdealSampler(),\n",
    "#             \"Moothedath, original\"                       : OptimumSampler(\n",
    "#                 mean_exec_time_estimator=FittedNaiveExecutionTimeModel(dist=stats.rayleigh).get_mean_execution_time,\n",
    "#                 alpha_calculator=lambda: tc * (Pc - P0),\n",
    "#                 beta_calculator=lambda: P0\n",
    "#             ),\n",
    "#             \"Moothedath et. al., superneurotic estimator\": OptimumSampler(\n",
    "#                 mean_exec_time_estimator=SuperNeuroticModel(neuroticism=1).get_mean_execution_time,\n",
    "#                 alpha_calculator=lambda: tc * (Pc - P0),\n",
    "#                 beta_calculator=lambda: P0\n",
    "#             )\n",
    "#         }\n",
    "#\n",
    "#     rows = deque()\n",
    "#\n",
    "#     for name, sampler in samplers.items():\n",
    "#         ground_truth.reset()\n",
    "#         prev_ttf = rtt\n",
    "#\n",
    "#         for step in range(1, task_steps + 1):\n",
    "#             exec_time = ground_truth.advance(prev_ttf).get_execution_time()\n",
    "#             sampling_result = sampler(exec_time, rtt)\n",
    "#             energy = calc_energy(sampling_result)\n",
    "#\n",
    "#             ttf = sampling_result.duration - exec_time\n",
    "#             wait_time = ttf - rtt\n",
    "#\n",
    "#             rows.append({\n",
    "#                 \"sampler\"    : name,\n",
    "#                 \"rtt\"        : rtt,\n",
    "#                 \"proc_time\"  : proc_t,\n",
    "#                 \"P0\"         : P0,\n",
    "#                 \"Pc\"         : Pc,\n",
    "#                 \"repetition\" : repetition,\n",
    "#                 \"step\"       : step,\n",
    "#                 \"exec_time\"  : exec_time,\n",
    "#                 \"duration\"   : sampling_result.duration,\n",
    "#                 \"ttf\"        : ttf,\n",
    "#                 \"wait_time\"  : wait_time,\n",
    "#                 \"energy\"     : energy,\n",
    "#                 \"num_samples\": sampling_result.num_samples,\n",
    "#             })\n",
    "#\n",
    "#             prev_ttf = ttf\n",
    "#\n",
    "#     df = pd.DataFrame(rows)\n",
    "#     df[\"sampler\"] = df[\"sampler\"].astype(pd.CategoricalDtype(samplers.keys(), ordered=False))\n",
    "#     return df\n",
    "#\n",
    "#\n",
    "# processing_delay = 0.15\n",
    "# rtts = np.array([0.2, 0.4, 0.8, 1.6, 3.2, 6.4])\n",
    "#\n",
    "# task_steps = 100\n",
    "# repetitions = 100\n",
    "#\n",
    "# P0 = 0.015\n",
    "# Pc = 0.045\n",
    "#\n",
    "# combinations = list(itertools.product(\n",
    "#     rtts,\n",
    "#     # [processing_delay],\n",
    "#     # [P0],\n",
    "#     # [Pc],\n",
    "#     # [task_steps],\n",
    "#     range(1, repetitions + 1)\n",
    "# ))\n",
    "#\n",
    "# results = deque()\n",
    "#\n",
    "# with tqdm(total=len(combinations)) as bar, mp.Pool() as pool:\n",
    "#     def _callback(df: pd.DataFrame):\n",
    "#         results.append(df)\n",
    "#         bar.update()\n",
    "#\n",
    "#\n",
    "#     def _errback(error):\n",
    "#         print(error)\n",
    "#         raise error\n",
    "#\n",
    "#\n",
    "#     for rtt, rep in combinations:\n",
    "#         pool.apply_async(\n",
    "#             superneurotic_experimental_run,\n",
    "#             args=(rtt, processing_delay, P0, Pc, task_steps, rep),\n",
    "#             callback=_callback,\n",
    "#             error_callback=_errback,\n",
    "#         )\n",
    "#\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "#\n",
    "# results = pd.concat(results, ignore_index=True)\n",
    "# results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# mean_energy_per_step = (\n",
    "#     results\n",
    "#     .groupby([\"sampler\", \"rtt\", \"repetition\"])\n",
    "#     [\"energy\"]\n",
    "#     .mean()\n",
    "#     # .groupby([\"sampler\", \"rtt\"])\n",
    "#     # .mean()\n",
    "# )\n",
    "#\n",
    "# plot_data = mean_energy_per_step.reset_index()\n",
    "# plot_data[\"rtt\"] = plot_data[\"rtt\"].apply(lambda s: f\"{s:0.2f} s\")\n",
    "#\n",
    "# fg = sns.catplot(\n",
    "#     kind=\"bar\",\n",
    "#     data=plot_data,\n",
    "#     x=\"energy\",\n",
    "#     y=\"sampler\",\n",
    "#     hue=\"rtt\",\n",
    "#     aspect=3,\n",
    "# )\n",
    "# fg.set_axis_labels(\"Mean energy consumed per step\", \"Sampler\")\n",
    "# fg.legend.set_title(\"RTT\")\n",
    "# for ax in fg.axes.flat:\n",
    "#     ax.xaxis.set_major_formatter(tkr.FuncFormatter(lambda x, p: f\"{x * 1000:1.0f} mJ\"))\n",
    "# plt.show()\n",
    "#\n",
    "# mean_energy_per_step"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
