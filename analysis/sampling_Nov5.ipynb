{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import itertools\n",
    "import warnings\n",
    "from collections import deque\n",
    "from typing import Dict\n",
    "\n",
    "import multiprocess as mp\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from edgedroid.models import *\n",
    "from sampling_util import *\n",
    "\n",
    "reference_name = \"Offline optimum\"\n",
    "\n",
    "\n",
    "def experimental_run(\n",
    "        rtt: float,\n",
    "        proc_t: float,\n",
    "        P0: float,\n",
    "        Pc: float,\n",
    "        task_steps: int,\n",
    "        repetition: int,\n",
    "):\n",
    "    tc = rtt - proc_t\n",
    "    w0 = 1.0\n",
    "    min_sr = 1 / (2 * w0)\n",
    "    alpha = 1.5\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ground_truths = {\n",
    "            \"low\" : ExpKernelRollingTTFETModel(neuroticism=0.0),\n",
    "            \"high\": ExpKernelRollingTTFETModel(neuroticism=1.0)\n",
    "        }\n",
    "\n",
    "        samplers: Dict[str, Dict[str, ConstantRTTSampler]] = {\n",
    "            \"Greedy\"                           : {\n",
    "                \"n/a\": GreedyConstantRTTSampler(\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            \"Wang et. al. 2019\\nGaussian fit\"  : {\n",
    "                \"n/a\": JunjuesConstantRTTSampler(\n",
    "                    cdf_estimator=FittedNaiveExecutionTimeModel(dist=stats.norm),\n",
    "                    min_sr=min_sr,\n",
    "                    alpha=alpha,\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            \"Sample-count-optimized\\naperiodic\": {\n",
    "                \"low\" : SamplingOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=0.0),\n",
    "                    max_wait=w0,\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                ),\n",
    "                \"high\": SamplingOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=1.0),\n",
    "                    max_wait=w0,\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            \"Energy-optimized\\naperiodic\"      : {\n",
    "                \"low\" : EnergyOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=0.0),\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                ),\n",
    "                \"high\": EnergyOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=1.0),\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            reference_name                     : {\n",
    "                \"n/a\": IdealConstantRTTSampler(\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "        }\n",
    "\n",
    "    rows = deque()\n",
    "\n",
    "    for (gt_level, ground_truth), (sampler_name, sampler_neuro_levels) in itertools.product(ground_truths.items(),\n",
    "                                                                                            samplers.items()):\n",
    "        for neuro_level, sampler in sampler_neuro_levels.items():\n",
    "            ground_truth.reset()\n",
    "            sampler.reset()\n",
    "            prev_ttf = rtt\n",
    "\n",
    "            for step in range(1, task_steps + 1):\n",
    "                exec_time = ground_truth.advance(prev_ttf).get_execution_time()\n",
    "                step_results: StepResults = sampler.sample_step(prev_ttf, exec_time)\n",
    "\n",
    "                rows.append(dict(\n",
    "                    ground_truth=gt_level,\n",
    "                    sampler=sampler_name,\n",
    "                    neuroticism=neuro_level,\n",
    "                    repetition=repetition,\n",
    "                    **step_results._asdict(),\n",
    "                ))\n",
    "                prev_ttf = step_results.ttf\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"sampler\"] = df[\"sampler\"].astype(pd.CategoricalDtype(samplers.keys(), ordered=False))\n",
    "    df[\"ground_truth\"] = df[\"ground_truth\"].astype(pd.CategoricalDtype([\"low\", \"high\"], ordered=True))\n",
    "    df[\"neuroticism\"] = df[\"neuroticism\"].astype(pd.CategoricalDtype([\"n/a\", \"low\", \"high\"], ordered=True))\n",
    "    return df\n",
    "\n",
    "\n",
    "processing_delay = 0.250\n",
    "rtts = np.linspace(0.3, 4.2, 14)\n",
    "net_delays = rtts - processing_delay\n",
    "\n",
    "task_steps = 100\n",
    "repetitions = 100\n",
    "\n",
    "P0 = 0.015\n",
    "Pc = 0.045\n",
    "\n",
    "combinations = list(itertools.product(\n",
    "    rtts,\n",
    "    range(1, repetitions + 1)\n",
    "))\n",
    "\n",
    "results = deque()\n",
    "\n",
    "with tqdm(total=len(combinations)) as bar, mp.Pool() as pool:\n",
    "    def _callback(df: pd.DataFrame):\n",
    "        results.append(df)\n",
    "        bar.update()\n",
    "\n",
    "\n",
    "    def _errback(error):\n",
    "        print(error)\n",
    "        raise error\n",
    "\n",
    "\n",
    "    for rtt, rep in combinations:\n",
    "        pool.apply_async(\n",
    "            experimental_run,\n",
    "            args=(rtt, processing_delay, P0, Pc, task_steps, rep),\n",
    "            callback=_callback,\n",
    "            error_callback=_errback,\n",
    "        )\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "results = pd.concat(results, ignore_index=True)\n",
    "results.to_parquet(\"./final_sampling_results.parquet.gzip\", compression=\"gzip\")\n",
    "results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# class SuperNeuroticModel(ExpKernelRollingTTFETModel):\n",
    "#     @staticmethod\n",
    "#     def get_data() -> Tuple[\n",
    "#         pd.DataFrame,\n",
    "#         pd.arrays.IntervalArray,\n",
    "#         pd.arrays.IntervalArray,\n",
    "#         pd.arrays.IntervalArray,\n",
    "#     ]:\n",
    "#         scaling_factor_min: float = 0.25\n",
    "#         scaling_factor_max: float = 4\n",
    "#\n",
    "#         data, *r = ExpKernelRollingTTFETModel.get_data()\n",
    "#         # print(data)\n",
    "#\n",
    "#         old_min = data[\"exec_time\"].min()\n",
    "#         old_max = data[\"exec_time\"].max()\n",
    "#\n",
    "#         new_min = old_min * scaling_factor_min\n",
    "#         new_max = old_max * scaling_factor_max\n",
    "#         new_range = new_max - new_min\n",
    "#\n",
    "#         data[\"exec_time\"] = (data[\"exec_time\"] - old_min) / (old_max - old_min)\n",
    "#         data[\"exec_time\"] = (data[\"exec_time\"] * new_range) + new_min\n",
    "#\n",
    "#         return data, *r\n",
    "#\n",
    "#\n",
    "# def superneurotic_experimental_run(\n",
    "#         rtt: float,\n",
    "#         proc_t: float,\n",
    "#         P0: float,\n",
    "#         Pc: float,\n",
    "#         task_steps: int,\n",
    "#         repetition: int,\n",
    "# ):\n",
    "#     tc = rtt - proc_t\n",
    "#     calc_energy = lambda result: calculate_energy(P0, Pc, tc, result)\n",
    "#\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\")\n",
    "#         ground_truth = SuperNeuroticModel(neuroticism=1.0)\n",
    "#         samplers: Dict[str, Sampler] = {\n",
    "#             \"Greedy\"                                     : GreedySampler(),\n",
    "#             \"Ideal\"                                      : IdealSampler(),\n",
    "#             \"Moothedath, original\"                       : OptimumSampler(\n",
    "#                 mean_exec_time_estimator=FittedNaiveExecutionTimeModel(dist=stats.rayleigh).get_mean_execution_time,\n",
    "#                 alpha_calculator=lambda: tc * (Pc - P0),\n",
    "#                 beta_calculator=lambda: P0\n",
    "#             ),\n",
    "#             \"Moothedath et. al., superneurotic estimator\": OptimumSampler(\n",
    "#                 mean_exec_time_estimator=SuperNeuroticModel(neuroticism=1).get_mean_execution_time,\n",
    "#                 alpha_calculator=lambda: tc * (Pc - P0),\n",
    "#                 beta_calculator=lambda: P0\n",
    "#             )\n",
    "#         }\n",
    "#\n",
    "#     rows = deque()\n",
    "#\n",
    "#     for name, sampler in samplers.items():\n",
    "#         ground_truth.reset()\n",
    "#         prev_ttf = rtt\n",
    "#\n",
    "#         for step in range(1, task_steps + 1):\n",
    "#             exec_time = ground_truth.advance(prev_ttf).get_execution_time()\n",
    "#             sampling_result = sampler(exec_time, rtt)\n",
    "#             energy = calc_energy(sampling_result)\n",
    "#\n",
    "#             ttf = sampling_result.duration - exec_time\n",
    "#             wait_time = ttf - rtt\n",
    "#\n",
    "#             rows.append({\n",
    "#                 \"sampler\"    : name,\n",
    "#                 \"rtt\"        : rtt,\n",
    "#                 \"proc_time\"  : proc_t,\n",
    "#                 \"P0\"         : P0,\n",
    "#                 \"Pc\"         : Pc,\n",
    "#                 \"repetition\" : repetition,\n",
    "#                 \"step\"       : step,\n",
    "#                 \"exec_time\"  : exec_time,\n",
    "#                 \"duration\"   : sampling_result.duration,\n",
    "#                 \"ttf\"        : ttf,\n",
    "#                 \"wait_time\"  : wait_time,\n",
    "#                 \"energy\"     : energy,\n",
    "#                 \"num_samples\": sampling_result.num_samples,\n",
    "#             })\n",
    "#\n",
    "#             prev_ttf = ttf\n",
    "#\n",
    "#     df = pd.DataFrame(rows)\n",
    "#     df[\"sampler\"] = df[\"sampler\"].astype(pd.CategoricalDtype(samplers.keys(), ordered=False))\n",
    "#     return df\n",
    "#\n",
    "#\n",
    "# processing_delay = 0.15\n",
    "# rtts = np.array([0.2, 0.4, 0.8, 1.6, 3.2, 6.4])\n",
    "#\n",
    "# task_steps = 100\n",
    "# repetitions = 100\n",
    "#\n",
    "# P0 = 0.015\n",
    "# Pc = 0.045\n",
    "#\n",
    "# combinations = list(itertools.product(\n",
    "#     rtts,\n",
    "#     # [processing_delay],\n",
    "#     # [P0],\n",
    "#     # [Pc],\n",
    "#     # [task_steps],\n",
    "#     range(1, repetitions + 1)\n",
    "# ))\n",
    "#\n",
    "# results = deque()\n",
    "#\n",
    "# with tqdm(total=len(combinations)) as bar, mp.Pool() as pool:\n",
    "#     def _callback(df: pd.DataFrame):\n",
    "#         results.append(df)\n",
    "#         bar.update()\n",
    "#\n",
    "#\n",
    "#     def _errback(error):\n",
    "#         print(error)\n",
    "#         raise error\n",
    "#\n",
    "#\n",
    "#     for rtt, rep in combinations:\n",
    "#         pool.apply_async(\n",
    "#             superneurotic_experimental_run,\n",
    "#             args=(rtt, processing_delay, P0, Pc, task_steps, rep),\n",
    "#             callback=_callback,\n",
    "#             error_callback=_errback,\n",
    "#         )\n",
    "#\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "#\n",
    "# results = pd.concat(results, ignore_index=True)\n",
    "# results"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# mean_energy_per_step = (\n",
    "#     results\n",
    "#     .groupby([\"sampler\", \"rtt\", \"repetition\"])\n",
    "#     [\"energy\"]\n",
    "#     .mean()\n",
    "#     # .groupby([\"sampler\", \"rtt\"])\n",
    "#     # .mean()\n",
    "# )\n",
    "#\n",
    "# plot_data = mean_energy_per_step.reset_index()\n",
    "# plot_data[\"rtt\"] = plot_data[\"rtt\"].apply(lambda s: f\"{s:0.2f} s\")\n",
    "#\n",
    "# fg = sns.catplot(\n",
    "#     kind=\"bar\",\n",
    "#     data=plot_data,\n",
    "#     x=\"energy\",\n",
    "#     y=\"sampler\",\n",
    "#     hue=\"rtt\",\n",
    "#     aspect=3,\n",
    "# )\n",
    "# fg.set_axis_labels(\"Mean energy consumed per step\", \"Sampler\")\n",
    "# fg.legend.set_title(\"RTT\")\n",
    "# for ax in fg.axes.flat:\n",
    "#     ax.xaxis.set_major_formatter(tkr.FuncFormatter(lambda x, p: f\"{x * 1000:1.0f} mJ\"))\n",
    "# plt.show()\n",
    "#\n",
    "# mean_energy_per_step"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
