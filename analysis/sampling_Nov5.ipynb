{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/500 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "642011a82eb5482aab0ec0bfe9ca764c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "       ground_truth          sampler neuroticism  repetition  execution_time  \\\n0               low           Greedy         n/a           3        3.815677   \n1               low           Greedy         n/a           3        4.429755   \n2               low           Greedy         n/a           3        4.407426   \n3               low           Greedy         n/a           3        5.631260   \n4               low           Greedy         n/a           3        4.281102   \n...             ...              ...         ...         ...             ...   \n699995         high  Offline optimum         n/a         100        7.554335   \n699996         high  Offline optimum         n/a         100        3.358096   \n699997         high  Offline optimum         n/a         100        4.789769   \n699998         high  Offline optimum         n/a         100        8.729351   \n699999         high  Offline optimum         n/a         100       10.582985   \n\n         duration     rtt       ttf     wait_time  num_samples    energy  \\\n0        4.387500  0.3375  0.571823  2.343230e-01           13  0.080438   \n1        5.062500  0.3375  0.632745  2.952447e-01           15  0.092813   \n2        5.062500  0.3375  0.655074  3.175742e-01           15  0.092813   \n3        6.075000  0.3375  0.443740  1.062396e-01           18  0.111375   \n4        4.725000  0.3375  0.443898  1.063977e-01           14  0.086625   \n...           ...     ...       ...           ...          ...       ...   \n699995  12.554335  5.0000  5.000000  0.000000e+00            1  0.329315   \n699996   8.358096  5.0000  5.000000  0.000000e+00            1  0.266371   \n699997   9.789769  5.0000  5.000000 -8.881784e-16            1  0.287847   \n699998  13.729351  5.0000  5.000000  0.000000e+00            1  0.346940   \n699999  15.582985  5.0000  5.000000  0.000000e+00            1  0.374745   \n\n           P0     Pc   t0      tc  \n0       0.015  0.045  0.3  0.0375  \n1       0.015  0.045  0.3  0.0375  \n2       0.015  0.045  0.3  0.0375  \n3       0.015  0.045  0.3  0.0375  \n4       0.015  0.045  0.3  0.0375  \n...       ...    ...  ...     ...  \n699995  0.015  0.045  0.3  4.7000  \n699996  0.015  0.045  0.3  4.7000  \n699997  0.015  0.045  0.3  4.7000  \n699998  0.015  0.045  0.3  4.7000  \n699999  0.015  0.045  0.3  4.7000  \n\n[700000 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ground_truth</th>\n      <th>sampler</th>\n      <th>neuroticism</th>\n      <th>repetition</th>\n      <th>execution_time</th>\n      <th>duration</th>\n      <th>rtt</th>\n      <th>ttf</th>\n      <th>wait_time</th>\n      <th>num_samples</th>\n      <th>energy</th>\n      <th>P0</th>\n      <th>Pc</th>\n      <th>t0</th>\n      <th>tc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>low</td>\n      <td>Greedy</td>\n      <td>n/a</td>\n      <td>3</td>\n      <td>3.815677</td>\n      <td>4.387500</td>\n      <td>0.3375</td>\n      <td>0.571823</td>\n      <td>2.343230e-01</td>\n      <td>13</td>\n      <td>0.080438</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.3</td>\n      <td>0.0375</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>low</td>\n      <td>Greedy</td>\n      <td>n/a</td>\n      <td>3</td>\n      <td>4.429755</td>\n      <td>5.062500</td>\n      <td>0.3375</td>\n      <td>0.632745</td>\n      <td>2.952447e-01</td>\n      <td>15</td>\n      <td>0.092813</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.3</td>\n      <td>0.0375</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>low</td>\n      <td>Greedy</td>\n      <td>n/a</td>\n      <td>3</td>\n      <td>4.407426</td>\n      <td>5.062500</td>\n      <td>0.3375</td>\n      <td>0.655074</td>\n      <td>3.175742e-01</td>\n      <td>15</td>\n      <td>0.092813</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.3</td>\n      <td>0.0375</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>low</td>\n      <td>Greedy</td>\n      <td>n/a</td>\n      <td>3</td>\n      <td>5.631260</td>\n      <td>6.075000</td>\n      <td>0.3375</td>\n      <td>0.443740</td>\n      <td>1.062396e-01</td>\n      <td>18</td>\n      <td>0.111375</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.3</td>\n      <td>0.0375</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>low</td>\n      <td>Greedy</td>\n      <td>n/a</td>\n      <td>3</td>\n      <td>4.281102</td>\n      <td>4.725000</td>\n      <td>0.3375</td>\n      <td>0.443898</td>\n      <td>1.063977e-01</td>\n      <td>14</td>\n      <td>0.086625</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.3</td>\n      <td>0.0375</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>699995</th>\n      <td>high</td>\n      <td>Offline optimum</td>\n      <td>n/a</td>\n      <td>100</td>\n      <td>7.554335</td>\n      <td>12.554335</td>\n      <td>5.0000</td>\n      <td>5.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.329315</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.3</td>\n      <td>4.7000</td>\n    </tr>\n    <tr>\n      <th>699996</th>\n      <td>high</td>\n      <td>Offline optimum</td>\n      <td>n/a</td>\n      <td>100</td>\n      <td>3.358096</td>\n      <td>8.358096</td>\n      <td>5.0000</td>\n      <td>5.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.266371</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.3</td>\n      <td>4.7000</td>\n    </tr>\n    <tr>\n      <th>699997</th>\n      <td>high</td>\n      <td>Offline optimum</td>\n      <td>n/a</td>\n      <td>100</td>\n      <td>4.789769</td>\n      <td>9.789769</td>\n      <td>5.0000</td>\n      <td>5.000000</td>\n      <td>-8.881784e-16</td>\n      <td>1</td>\n      <td>0.287847</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.3</td>\n      <td>4.7000</td>\n    </tr>\n    <tr>\n      <th>699998</th>\n      <td>high</td>\n      <td>Offline optimum</td>\n      <td>n/a</td>\n      <td>100</td>\n      <td>8.729351</td>\n      <td>13.729351</td>\n      <td>5.0000</td>\n      <td>5.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.346940</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.3</td>\n      <td>4.7000</td>\n    </tr>\n    <tr>\n      <th>699999</th>\n      <td>high</td>\n      <td>Offline optimum</td>\n      <td>n/a</td>\n      <td>100</td>\n      <td>10.582985</td>\n      <td>15.582985</td>\n      <td>5.0000</td>\n      <td>5.000000</td>\n      <td>0.000000e+00</td>\n      <td>1</td>\n      <td>0.374745</td>\n      <td>0.015</td>\n      <td>0.045</td>\n      <td>0.3</td>\n      <td>4.7000</td>\n    </tr>\n  </tbody>\n</table>\n<p>700000 rows Ã— 15 columns</p>\n</div>"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import warnings\n",
    "from collections import deque\n",
    "from typing import Dict\n",
    "\n",
    "import multiprocess as mp\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from edgedroid.models import *\n",
    "from sampling_util import *\n",
    "\n",
    "reference_name = \"Offline optimum\"\n",
    "\n",
    "\n",
    "def experimental_run(\n",
    "        rtt: float,\n",
    "        proc_t: float,\n",
    "        P0: float,\n",
    "        Pc: float,\n",
    "        task_steps: int,\n",
    "        repetition: int,\n",
    "):\n",
    "    tc = rtt - proc_t\n",
    "    w0 = 1.0\n",
    "    min_sr = 1 / (2 * w0)\n",
    "    alpha = 3.0\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        ground_truths = {\n",
    "            \"low\" : ExpKernelRollingTTFETModel(neuroticism=0.0),\n",
    "            \"high\": ExpKernelRollingTTFETModel(neuroticism=1.0)\n",
    "        }\n",
    "\n",
    "        samplers: Dict[str, Dict[str, ConstantRTTSampler]] = {\n",
    "            \"Greedy\"                           : {\n",
    "                \"n/a\": GreedyConstantRTTSampler(\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            \"Wang et. al. 2019\\nGaussian fit\"  : {\n",
    "                \"n/a\": JunjuesConstantRTTSampler(\n",
    "                    cdf_estimator=FittedNaiveExecutionTimeModel(dist=stats.norm),\n",
    "                    min_sr=min_sr,\n",
    "                    alpha=alpha,\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            \"Sample-count-optimized\\naperiodic\": {\n",
    "                \"low\" : SamplingOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=0.0),\n",
    "                    max_wait=w0,\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                ),\n",
    "                \"high\": SamplingOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=1.0),\n",
    "                    max_wait=w0,\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            \"Energy-optimized\\naperiodic\"      : {\n",
    "                \"low\" : EnergyOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=0.0),\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                ),\n",
    "                \"high\": EnergyOptimumSampler(\n",
    "                    estimator=ExpKernelRollingTTFETModel(neuroticism=1.0),\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "            reference_name                     : {\n",
    "                \"n/a\": IdealConstantRTTSampler(\n",
    "                    t_net=tc,\n",
    "                    t_proc=proc_t,\n",
    "                    P0=P0,\n",
    "                    Pc=Pc\n",
    "                )\n",
    "            },\n",
    "        }\n",
    "\n",
    "    rows = deque()\n",
    "\n",
    "    for (gt_level, ground_truth), (sampler_name, sampler_neuro_levels) in itertools.product(ground_truths.items(),\n",
    "                                                                                            samplers.items()):\n",
    "        for neuro_level, sampler in sampler_neuro_levels.items():\n",
    "            ground_truth.reset()\n",
    "            sampler.reset()\n",
    "            prev_ttf = rtt\n",
    "\n",
    "            for step in range(1, task_steps + 1):\n",
    "                exec_time = ground_truth.advance(prev_ttf).get_execution_time()\n",
    "                step_results: StepResults = sampler.sample_step(prev_ttf, exec_time)\n",
    "\n",
    "                rows.append(dict(\n",
    "                    ground_truth=gt_level,\n",
    "                    sampler=sampler_name,\n",
    "                    neuroticism=neuro_level,\n",
    "                    repetition=repetition,\n",
    "                    **step_results._asdict(),\n",
    "                ))\n",
    "                prev_ttf = step_results.ttf\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"sampler\"] = df[\"sampler\"].astype(pd.CategoricalDtype(samplers.keys(), ordered=False))\n",
    "    df[\"ground_truth\"] = df[\"ground_truth\"].astype(pd.CategoricalDtype([\"low\", \"high\"], ordered=True))\n",
    "    df[\"neuroticism\"] = df[\"neuroticism\"].astype(pd.CategoricalDtype([\"n/a\", \"low\", \"high\"], ordered=True))\n",
    "    return df\n",
    "\n",
    "\n",
    "processing_delay = 0.3\n",
    "rtts = np.array([0.3375, 0.675, 1.25, 2.5, 5.0])\n",
    "net_delays = rtts - processing_delay\n",
    "\n",
    "task_steps = 100\n",
    "repetitions = 100\n",
    "\n",
    "P0 = 0.015\n",
    "Pc = 0.045\n",
    "\n",
    "combinations = list(itertools.product(\n",
    "    rtts,\n",
    "    range(1, repetitions + 1)\n",
    "))\n",
    "\n",
    "results = deque()\n",
    "\n",
    "with tqdm(total=len(combinations)) as bar, mp.Pool() as pool:\n",
    "    def _callback(df: pd.DataFrame):\n",
    "        results.append(df)\n",
    "        bar.update()\n",
    "\n",
    "\n",
    "    def _errback(error):\n",
    "        print(error)\n",
    "        raise error\n",
    "\n",
    "\n",
    "    for rtt, rep in combinations:\n",
    "        pool.apply_async(\n",
    "            experimental_run,\n",
    "            args=(rtt, processing_delay, P0, Pc, task_steps, rep),\n",
    "            callback=_callback,\n",
    "            error_callback=_errback,\n",
    "        )\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "results = pd.concat(results, ignore_index=True)\n",
    "results.to_parquet(\"./final_sampling_results.parquet.gzip\", compression=\"gzip\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# class SuperNeuroticModel(ExpKernelRollingTTFETModel):\n",
    "#     @staticmethod\n",
    "#     def get_data() -> Tuple[\n",
    "#         pd.DataFrame,\n",
    "#         pd.arrays.IntervalArray,\n",
    "#         pd.arrays.IntervalArray,\n",
    "#         pd.arrays.IntervalArray,\n",
    "#     ]:\n",
    "#         scaling_factor_min: float = 0.25\n",
    "#         scaling_factor_max: float = 4\n",
    "#\n",
    "#         data, *r = ExpKernelRollingTTFETModel.get_data()\n",
    "#         # print(data)\n",
    "#\n",
    "#         old_min = data[\"exec_time\"].min()\n",
    "#         old_max = data[\"exec_time\"].max()\n",
    "#\n",
    "#         new_min = old_min * scaling_factor_min\n",
    "#         new_max = old_max * scaling_factor_max\n",
    "#         new_range = new_max - new_min\n",
    "#\n",
    "#         data[\"exec_time\"] = (data[\"exec_time\"] - old_min) / (old_max - old_min)\n",
    "#         data[\"exec_time\"] = (data[\"exec_time\"] * new_range) + new_min\n",
    "#\n",
    "#         return data, *r\n",
    "#\n",
    "#\n",
    "# def superneurotic_experimental_run(\n",
    "#         rtt: float,\n",
    "#         proc_t: float,\n",
    "#         P0: float,\n",
    "#         Pc: float,\n",
    "#         task_steps: int,\n",
    "#         repetition: int,\n",
    "# ):\n",
    "#     tc = rtt - proc_t\n",
    "#     calc_energy = lambda result: calculate_energy(P0, Pc, tc, result)\n",
    "#\n",
    "#     with warnings.catch_warnings():\n",
    "#         warnings.simplefilter(\"ignore\")\n",
    "#         ground_truth = SuperNeuroticModel(neuroticism=1.0)\n",
    "#         samplers: Dict[str, Sampler] = {\n",
    "#             \"Greedy\"                                     : GreedySampler(),\n",
    "#             \"Ideal\"                                      : IdealSampler(),\n",
    "#             \"Moothedath, original\"                       : OptimumSampler(\n",
    "#                 mean_exec_time_estimator=FittedNaiveExecutionTimeModel(dist=stats.rayleigh).get_mean_execution_time,\n",
    "#                 alpha_calculator=lambda: tc * (Pc - P0),\n",
    "#                 beta_calculator=lambda: P0\n",
    "#             ),\n",
    "#             \"Moothedath et. al., superneurotic estimator\": OptimumSampler(\n",
    "#                 mean_exec_time_estimator=SuperNeuroticModel(neuroticism=1).get_mean_execution_time,\n",
    "#                 alpha_calculator=lambda: tc * (Pc - P0),\n",
    "#                 beta_calculator=lambda: P0\n",
    "#             )\n",
    "#         }\n",
    "#\n",
    "#     rows = deque()\n",
    "#\n",
    "#     for name, sampler in samplers.items():\n",
    "#         ground_truth.reset()\n",
    "#         prev_ttf = rtt\n",
    "#\n",
    "#         for step in range(1, task_steps + 1):\n",
    "#             exec_time = ground_truth.advance(prev_ttf).get_execution_time()\n",
    "#             sampling_result = sampler(exec_time, rtt)\n",
    "#             energy = calc_energy(sampling_result)\n",
    "#\n",
    "#             ttf = sampling_result.duration - exec_time\n",
    "#             wait_time = ttf - rtt\n",
    "#\n",
    "#             rows.append({\n",
    "#                 \"sampler\"    : name,\n",
    "#                 \"rtt\"        : rtt,\n",
    "#                 \"proc_time\"  : proc_t,\n",
    "#                 \"P0\"         : P0,\n",
    "#                 \"Pc\"         : Pc,\n",
    "#                 \"repetition\" : repetition,\n",
    "#                 \"step\"       : step,\n",
    "#                 \"exec_time\"  : exec_time,\n",
    "#                 \"duration\"   : sampling_result.duration,\n",
    "#                 \"ttf\"        : ttf,\n",
    "#                 \"wait_time\"  : wait_time,\n",
    "#                 \"energy\"     : energy,\n",
    "#                 \"num_samples\": sampling_result.num_samples,\n",
    "#             })\n",
    "#\n",
    "#             prev_ttf = ttf\n",
    "#\n",
    "#     df = pd.DataFrame(rows)\n",
    "#     df[\"sampler\"] = df[\"sampler\"].astype(pd.CategoricalDtype(samplers.keys(), ordered=False))\n",
    "#     return df\n",
    "#\n",
    "#\n",
    "# processing_delay = 0.15\n",
    "# rtts = np.array([0.2, 0.4, 0.8, 1.6, 3.2, 6.4])\n",
    "#\n",
    "# task_steps = 100\n",
    "# repetitions = 100\n",
    "#\n",
    "# P0 = 0.015\n",
    "# Pc = 0.045\n",
    "#\n",
    "# combinations = list(itertools.product(\n",
    "#     rtts,\n",
    "#     # [processing_delay],\n",
    "#     # [P0],\n",
    "#     # [Pc],\n",
    "#     # [task_steps],\n",
    "#     range(1, repetitions + 1)\n",
    "# ))\n",
    "#\n",
    "# results = deque()\n",
    "#\n",
    "# with tqdm(total=len(combinations)) as bar, mp.Pool() as pool:\n",
    "#     def _callback(df: pd.DataFrame):\n",
    "#         results.append(df)\n",
    "#         bar.update()\n",
    "#\n",
    "#\n",
    "#     def _errback(error):\n",
    "#         print(error)\n",
    "#         raise error\n",
    "#\n",
    "#\n",
    "#     for rtt, rep in combinations:\n",
    "#         pool.apply_async(\n",
    "#             superneurotic_experimental_run,\n",
    "#             args=(rtt, processing_delay, P0, Pc, task_steps, rep),\n",
    "#             callback=_callback,\n",
    "#             error_callback=_errback,\n",
    "#         )\n",
    "#\n",
    "#     pool.close()\n",
    "#     pool.join()\n",
    "#\n",
    "# results = pd.concat(results, ignore_index=True)\n",
    "# results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# mean_energy_per_step = (\n",
    "#     results\n",
    "#     .groupby([\"sampler\", \"rtt\", \"repetition\"])\n",
    "#     [\"energy\"]\n",
    "#     .mean()\n",
    "#     # .groupby([\"sampler\", \"rtt\"])\n",
    "#     # .mean()\n",
    "# )\n",
    "#\n",
    "# plot_data = mean_energy_per_step.reset_index()\n",
    "# plot_data[\"rtt\"] = plot_data[\"rtt\"].apply(lambda s: f\"{s:0.2f} s\")\n",
    "#\n",
    "# fg = sns.catplot(\n",
    "#     kind=\"bar\",\n",
    "#     data=plot_data,\n",
    "#     x=\"energy\",\n",
    "#     y=\"sampler\",\n",
    "#     hue=\"rtt\",\n",
    "#     aspect=3,\n",
    "# )\n",
    "# fg.set_axis_labels(\"Mean energy consumed per step\", \"Sampler\")\n",
    "# fg.legend.set_title(\"RTT\")\n",
    "# for ax in fg.axes.flat:\n",
    "#     ax.xaxis.set_major_formatter(tkr.FuncFormatter(lambda x, p: f\"{x * 1000:1.0f} mJ\"))\n",
    "# plt.show()\n",
    "#\n",
    "# mean_energy_per_step"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
